# -*- coding: utf-8 -*-
"""ans_to_que.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u6fGykDzsdktcGNY1otn08IVG85D47ic
"""

import pandas as pd
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

# Load tokenizer and model
tokenizer = AutoTokenizer.from_pretrained("mrm8488/t5-base-finetuned-question-generation-ap")
model = AutoModelForSeq2SeqLM.from_pretrained("mrm8488/t5-base-finetuned-question-generation-ap")

df = pd.read_csv("/content/drive/MyDrive/eiffel_dataset.csv")
context = df.loc[0, "context"]
print("\n Eiffel Tower Context:\n")
print(context)

answer = input("\n Enter the answer (from the above context):\n> ")

input_text = f"answer: {answer} context: {context}"
input_ids = tokenizer.encode(input_text, return_tensors="pt")

output_ids = model.generate(input_ids, max_length=64, num_beams=4, early_stopping=True)
question = tokenizer.decode(output_ids[0], skip_special_tokens=True)

print("\n Generated Question:", question)